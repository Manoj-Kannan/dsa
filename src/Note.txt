Introduction:
Abstract Data Type  - interface         =   What are the expected behaviour from the user point of view
                                        -   (e.g. queue needs enque & deque mechanisms)
Data Structures     - implementation    -   How the behaviours are exhibited
                                        -   (e.g. queue can be implemented ny use of list)

Note:
Data Structures:::
Arrays      -   index based
            -   predefined size (allocates sections within the memory)
            -   ideal for item retrieval (if index is known)

LinkedList  -   reference based
            -   dynamic size
            -   ideal for insertion & deletion

Doubly LinkedList   -   variation of LinkedList, where each element points to both the next & previous item
                    -   can be easily traversed in forward & reverse direction
                    -   adding or removing element from a DLL is more efficient than LL (since we need not keep track of previod node separately)
                    -   extra memory is need (since we store the previous node also)

Stack       -   Abstract Data Type
            -   implemented using Array / Linked List
            -   follows Last-In-First-Out Mechanism (LIFO)
            -   Useful in Memory Management (Stack Memory), recursion, Undo Mechanism

Queue       -   Abstract Data Type
            -   implemented using Array / Linked List
            -   follows First-In-First-Out Mechanism (FIFO)
            -   Useful in CPU task Scheduling, BFS

Map         -   Abstract Data Type
            -   Mostly implemented using HashTables (contains slot for storing data)
            -   or can be implemented using Trees
            -   Hashing (hashes a key to an index) (elements can be retrieved using same hash (O(1) TimeComplexity))
            -   Collision - A new key is put into the map where the map already contains the same key.
                -   Chaining:
                    -   Both the elements are stored in LinkedList (one after the other) at same hash index.
                    -   When we try to retrieve the value for the key, we need to iterate through the LL. (becomes O(N) TimeComplexity)
                -   Open-Addressing:
                    -   Makes use of Probing mechanism to avoid collision (searches for an empty slot)
                    -   Linear Probing
                    -   Quadratic Probing
                    -   Double Probing
                -   Finally,
                    -   In Chaining Mechanism, item will be stored somewhere in the Array (find by hash)/ somewhere in the ArrayList (loop over the LL)
                    -   In Probing, only one item sill be present in a index (find only by hash)

Graph       -   a collection of nodes that have data and are connected to other nodes
            -   a node is called "Vertex", connection between nodes is called "Edge", nodes directly linked to a node are called "Neighbours"
            -   Adjacent/ Non-Adjacent:
                -   Adjacent    :   2 Nodes connected directly with edges
                -   Non-Adjacent:   2 Nodes not connected directly with edges (a node connected with its grand-parent)
            -   Directed/ UnDirected:
                -   UnDirected  :   2 Nodes are traversed in Forward & Reverse Direction (A -> B, B -> A)
                -   Directed    :   2 Nodes are traversed in Forward or Reverse Direction only (A -> B (or) B -> A)
            -   Strongly/ Weekly Connected:
                -   Strongly    -   graph in which there is a path from each vertex to reach another vertex
                -   Weekly      -   graph in which a vertex cant be reached another
            -   Cycle:
                -   a cycle is detected if a path can be established where only the first & last vertex are repeated
                -   a cycle is a connected & UnDirected graph
            -   Representation of Graph:
                -   Adjacency Matrix:
                    -   a 2D array of V x V vertices. Each row and column represent a vertex
                    -   the value of any element a[i][j] is 1, it represents that there is an edge connecting vertex i and vertex j
                -   Adjacency List:
                    -   An adjacency list represents a graph as an array of linked lists
                    -   The index of the array represents a vertex and each element in its linked list represents the other vertices that form an edge with the vertex
            -   Spanning Tree:
                -   a sub-graph of a undirected, cyclic, connected graph, which includes all vertices with minimum possible number of edges (no vertex should be missed)
                -   Graph is converted to a tree (Directed Acyclic Graph) with less cost (sum of weights to move between all nodes)
                -   eg: No of Nodes - 4,
                    -   if No of Edges = n = 4, it is a graph (cycle formed)
                    -   if No of Edges = (n-1) = 3, it is a tree (no cycle formed)
                    -   No of Spanning Trees (that can be formed) = (n^(n-2)) = 16
                    -   So, goal is to reduce no. of edges of a graph and to create a tree.
                -   implemented using Priority Queues & Weighted Graphs
                -   Applications: Network Routing Protocols, CLuster Analysis

Breadth First Search    -   traverses a graph by visiting every vertex only once
                        -   must mention the starting vertex to the algorithm (root node)
                        -   explores all the neighbours of the currNode before moving to the next depth level
                        -   implemented using Queue (FIFO)
                            -   when a vertex is discovered it is added to queue
                            -   remove parent vertex (first vertex in queue) & add neighbouring vertices of parent vertex to queue
                            -   when the queue becomes empty, the graph is completely traversed

Depth First Search      -   traverses a graph by visiting every vertex only once
                        -   goes down as far as it can in the given path, then backtracks to closest parent (until it finds another unexplored path and visits it)
                        -   implemented using Stack (LIFO)
                            -   when a vertex is discovered it is added to stack
                            -   pop the parent vertex (visited) & add all its neighbours to stack (non-visited)
                            -   for each neighbour perform step 2 iteratively
                        -   response order may vary based the order of traversal through child vertices

Difference:
BFS     -   Traverses layer by layer
DFS     -   Traverses one complete branch & moves to another branch

Dijkstra Algorithm      -   finds the shortest path between 2 vertices of a graph
                        -   Application: Social Networks, Google Maps, IP Routing
                        -   Any sub-path between the Start & End Vertex, should be the shortest path between 2 vertices
                        -   e.g. a graph with vertices A, B, C, D. Aim is to find the shortest path from A to D.
                            Solution is A -> B -> C -> D
                            Which means, Shortest path from A to C should be A -> B -> C
                                         Shortest path from B to D should be B -> C -> D

                        -   Implementation:
                            -   the core idea is to eliminate longer paths between the starting node and all possible destinations
                            -   Vertices are classified as
                                -   Settled (minimum distance & predecessor (with min distance) are finalised
                                -   UnSettled (can be reached from source but minimum distance is not finalised)
                            -   Iteratively remove all paths with long distances until we mark all UnSettled Vertices as Settled

Ford-Fulkerson Algo     -   determine Maximum Flow in a network
                        -   flow network is used to describe a network of vertices and edges with a source (S) and a sink (T)
                        -   S can only send and T can only receive stuff. All other vertices can receive and send an equal amount of stuff through it.
                        -   Terminologies;
                            -   Augmenting Path: It is the path available in a flow network.
                            -   Residual Graph: It represents the flow network that has additional possible flow.
                            -   Residual Capacity: It is the capacity of the edge after subtracting the flow from the maximum capacity.
                        -   Working:
                            -   Initialize the flow in all the edges to 0
                            -   While there is an augmenting path between the source and the sink, add this path to the flow (e can also consider reverse-path
                            -   Update the residual graph
                        -   Explanation:
                            -   Select any arbitrary path from S to T
                            -   Find the minimum capacity in the chosen arbitrary path (it represents the maximum flow in the path)
                            -   Update the capacities accordingly (Residual Capacity) -> Formula = Total Capacity of Vertex - Flow from previous path
                            -   Select another path from S to T
                            -   Repeat the above steps...
                            -   (if the capacity for any edge is full, then that path cannot be used)

Trees       -   Undirected, Connected, Acyclic Graphs
            -   Node
                -   A node is an entity that contains a key or value and pointers to its child nodes.
                -   The last nodes of each path are called leaf nodes that do not contain a link/pointer to child nodes.
            -   Edge
                -   It is the link between any two nodes.
            -   Root
                -   It is the topmost node of a tree.
            -   Depth of a Node (top to down - depth of root - 0, depth of first child - 1, depth of grand child (from root) - 2)
                -   The depth of a node is the number of edges from the root to the node.
            -   Height of a Node
                -   The height of a node is the number of edges from the node to the deepest leaf (i.e. the longest path from the node to a leaf node)
            -   Height of a Tree (down to top - height of grand child (from root) - 0, height of parent (child of root) - 1, height of root - 2)
                -   Reverse of depth
                -   The height of a Tree is the height of the root node or the depth of the deepest node.
            -   To be a tree, a node can be reached in only one direction (i.e. no. of edges = no. of nodes - 1)

Tree Traversal  -   Inorder traversal (Root middle)
                    -   Visit all the nodes in the left subtree
                    -   Then the root node
                    -   Visit all the nodes in the right subtree
                -   Preorder traversal (Root first)
                    -   Visit root node
                    -   Visit all the nodes in the left subtree
                    -   Visit all the nodes in the right subtree
                -   Postorder traversal (Root last)
                    -   Visit all the nodes in the left subtree
                    -   Visit all the nodes in the right subtree
                    -   Visit the root node

Binary Tree -   A binary tree is a tree data structure in which each parent node can have at most two children or no children

Binary Search Tree  -   It is called a binary tree because each tree node has a maximum of two children.
                    -   The properties that separate a binary search tree from a regular binary tree is
                            -   All nodes of left subtree are less than the root node
                            -   All nodes of right subtree are more than the root node
                            -   Both subtrees of each node are also BSTs i.e. they have the above two properties
                    -   Refer : https://www.programiz.com/dsa/binary-search-tree

AVL Tree    -   If the tree is not a balanced tree (tree contains only right sub-tree or only left sub-tree), the performance of BST decreases.
            -   AVL tree is a self-balancing binary search tree in which each node maintains extra information called a balance factor whose value is either -1, 0 or +1.
            -   Balance Factor
                -   Balance factor of a node in an AVL tree is the difference between the height of the left subtree and that of the right subtree of that node.
                -   Balance Factor = Height of Left Subtree - Height of Right Subtree
                -   The value of balance factor should always be -1, 0 or +1.

            -   Rotations
                -   Rotations are fundamental operations used in AVL trees to maintain balance after insertion or deletion of nodes.
                -   Imbalance always occurs in grandparent (root) node (can be determined by balance of root node)
                -   Rotations are done only on 3 nodes, including the unbalanced node.
                -   Left Rotation (anti-clockwise rotation)
                    -   Caused due to Right-Right Insertion of New-Node
                    -   imbalance in right child and right sub-tree
                    -   solves Right-Heavy Situation --> balance factor < -1 (-ve)
                    -   If a node is added to the right subtree of the right subtree, if the tree gets out of balance, we do a single left rotation.
                    -   e.g. 10, 20, and 30
                -   Right Rotation (clockwise rotation)
                    -   Caused due to Left-Left Insertion of New-Node
                    -   imbalance in left child and left sub-tree
                    -   solves Left-Heavy Situation --> balance factor > 1 (+ve)
                    -   If a node is added to the left subtree of the left subtree, the AVL tree may get out of balance, we do a single right rotation.
                    -   e.g. 30, 20, and 10
                -   Right-Left Rotation
                    -   Caused due to Right-Left Insertion of New-Node
                    -   imbalance in right child and left sub-tree
                    -   balance of parent - +ve, balance of grandparent - -ve (parent - parent of newly inserted node, grandparent - parent of parent of newly inserted node)
                    -   Steps:
                        -   Solve Left-Heavy Situation in Parent (+ve balance) with Right Rotation
                        -   Solve Right-Heavy Situation in GrandParent (-ve balance) with Left Rotation
                    -   e.g. 20, 30, and 10
                -   Left-Right Rotation
                    -   Caused due to Left-Right Insertion of New-Node
                    -   imbalance in left child and right sub-tree
                    -   balance of parent - -ve, balance of grandparent - +ve
                    -   Steps:
                        -   Solve Right-Heavy Situation in Parent (-ve balance) with Left Rotation
                        -   Solve Left-Heavy Situation in GrandParent (+ve balance) with Right Rotation
                    -   e.g. 30, 10, and 20

                - Summary
                    -   child - newly inserted node, parent - parent of newly inserted node, grandparent - parent of parent of newly inserted node
                    -   Left-Left Insertion     -   imbalance in grandparent        -   perform Right Rotation on grandparent
                    -   Right-Right Insertion   -   imbalance in grandparent        -   perform Left Rotation on grandparent
                    -   Left-Right Insertion    -   imbalance in grandparent
                                         1st    -   imbalance in parent (-ve)       -   perform Left Rotation on parent
                                         2nd    -   imbalance in grandparent (+ve)  -   perform Right Rotation on grandparent
                    -   Right-Left Insertion    -   imbalance in grandparent
                                         1st    -   imbalance in parent (+ve)       -   perform Right Rotation on parent
                                         2nd    -   imbalance in grandparent (-ve)  -   perform left Rotation on grandparent

            -   Operations
                -   Insertion
                        1 -> START
                        2 -> Insert the node using BST insertion logic.
                        3 -> Calculate and check the balance factor of each node.
                        4 -> If the balance factor follows the AVL criterion, go to step 6
                        5 -> Else, perform tree rotations according to the insertion done. Once the tree is balanced go to step 6.
                        6 -> END
                -   Deletion
                    -   Similar to BST

Red-Black Tree  -   Red-Black Trees are balanced binary search trees where nodes are colored red or black.
                -   Conditions
                    -   The root node is black.
                    -   Every tree leaf node is always black.
                    -   Every red node must have black children.
                    -   There are no two adjacent red nodes (A red node cannot have a red parent or red child).
                    -   For each node, all paths from the node to its descendant leaves contain the same number of black nodes (ensures that the tree remains balanced)
                -   Operations
                    -   Insertion
                        -   When a new node is inserted into a red-black tree, it is initially colored red.
                        -   After insertion, if the tree violates any of the red-black tree properties, a series of rotations and recoloring operations are performed to restore balance.
                        -   The insertion algorithm ensures that the black depth property is maintained and that no two consecutive red nodes exist along any path

                        -   Cases Requiring Recoloring and Rotations
                            -   Case 1: Red-Red Violation - Parent's Sibling is Red (Uncle is Red)
                                -   Scenario: After inserting a new red node, if its parent is also red (i.e., red-red violation), and the uncle of the new node (the sibling of the parent) is also red.
                                -   Solution: In this case, recoloring is done to balance the tree. The parent and the uncle of the new node are colored black, while the grandparent (parent's parent) is colored red. This effectively moves the red-red violation up the tree. Then, we check if the properties are still violated higher up the tree.
                                -   Actions: Recoloring
                            -   Case 2: Red-Red Violation - Parent's Sibling is Black (Uncle is Black or Null)
                                -   Scenario: After inserting a new red node, if its parent is red and the uncle of the new node (the sibling of the parent) is black or null.
                                -   Solution: This situation requires rotations and possibly recoloring to maintain the red-black properties.
                                    -   If the new node and its parent are not on the same side (one is a left child and the other is a right child), double rotation (left-right or right-left rotation) may be necessary.
                                    -   If the new node and its parent are on the same side (both are left children or both are right children), a single rotation (left-left or right-right rotation) may be sufficient.
                                    -   In other words,
                                        -   if parent is left-child from grandparent, ends in left-heavy or left-right situation
                                        -   if parent is right-child from grandparent, ends in right-heavy or right-left situation
                                -   Actions: Rotations and possibly recoloring
                            -   Case 3: Root Node Violation
                                -   Scenario: After insertion, if the root node becomes red, it violates the property that the root must be black.
                                -   Solution: Simply recolor the root node to black.
                                -   Actions: Recoloring
                        -   Summary of Actions
                            -   Recoloring: Changing the color of one or more nodes to restore the red-black properties.
                            -   Rotations: Reorganizing the structure of the tree to maintain balance.

                    -   Deletion
                        -   Similar to BST & validate properties of Red-Black Tree
                        -   Cases Requiring Recoloring and Rotations:
                            -   Case 1: Black Node Deletion - Black Height Violation
                                -   Scenario: After deleting a black node, if one of its child nodes is red, the black height of the tree decreases on the subtree rooted at the sibling of the deleted node.
                                -   Solution: This situation requires rebalancing through recoloring and rotations to ensure that the black height property is maintained.
                                -   Actions: Recoloring and/or rotations
                            -   Case 2: Double Black Node Deletion
                                -   Scenario: The "double black" situation occurs in a red-black tree after a black node is deleted, resulting in a violation of the red-black properties. When a black node is removed, it can lead to a decrease in the black height of one or more paths in the tree, causing an imbalance.
                                -   Consequences: The presence of a "double black" node violates the red-black properties, particularly the black height property, which states that all paths from a node to its descendant leaves must contain the same number of black nodes.
                                -   Handling the Double Black Situation: The goal is to redistribute or transfer the "double blackness" to other parts of the tree while maintaining the red-black properties.
                    -   Refer   :   https://www.scaler.com/topics/data-structures/red-black-tree/, https://www.geeksforgeeks.org/insertion-in-red-black-tree/

Heap Tree       -   a special case of balanced binary tree data structure (the last level is completely filled (or) filled from left to right, which might not be fully complete)
                -   the root-node key is compared with its children and arranged accordingly
                -   Types
                    -   Min-Heap − Where the value of the root node is less than or equal to either of its children.
                    -   Max-Heap − Where the value of the root node is greater than or equal to either of its children.
                -   Implementation
                    -   Heap Tree is represented using array
                    -   Formulas to find parent-child relationship
                        -   leftChild of parent = (2 * parentIndex) + 1
                        -   rightChild of parent = (2 * parentIndex) + 2
                        -   parentIndex of child = (childIndex - 1) / 2
                -	Heap Operations
                	-	Insertion:
                		-	Add the new element at the end of the array.
                		-	Heapify up: Compare the added element with its parent; if the added element is larger (for max heap), swap them.
                            Repeat until the heap property is restored.
                	-	Deletion (Removing the root):
                		-	Replace the root with the last element in the array.
                		-	Remove the last element.
                		-	Heapify down: Compare the new root with its children; if it's smaller (for max heap), swap it with the larger child.
                		    Repeat until the heap property is restored.

Trie            -   tree-like data structure that stores a dynamic set of strings, where the keys are usually strings
                -	Characteristics of Trie
                	-	Nodes and Edges: Each node represents a character of the string, and each edge represents the transition between characters.
                	-	Root Node: Represents an empty string.
                	-	Children: Each node can have multiple children, and each child node represents a subsequent character in a string.
                	-	End-of-Word Marker: Special markers or flags in the nodes to indicate the end of a valid word.
                -	Advantages of Trie
                	-	Prefix Search: Efficient for searching words that share common prefixes.
                	-	Auto-complete: Useful in applications like auto-complete, spell checkers, and IP routing.
                	-	Space Efficiency: Can be more space-efficient than storing all words separately if many words share common prefixes.
                -   Applications
                    -   Spell Checkers, Dictionary Implementation, Search Engine Indexing, Data Compression, IP Routing, Dynamic String Matching



Sorting Algorithms::: (Refer : Programiz, Scaler Topics (https://www.scaler.com/topics/data-structures/))
Bubble Sort     -   compares two adjacent elements and swaps them until they are in the intended order
                -   Steps
                    -	Starting from the first index, compare the first and the second elements.
                    -	If the first element is greater than the second element, they are swapped.
                    -	Now, compare the second and the third elements. Swap them if they are not in order.
                    -	The above process goes on until the last element.
                -   Note
                    -   After each iteration, the largest element among the unsorted elements is placed at the end.

Selection Sort  -   works on the idea of repeatedly finding the smallest element and placing it at its correct sorted position.
                -   It basically selects the smallest element from an unsorted array in each iteration and places that element at the beginning of the unsorted array.
                -   Steps
                    -	Initially, our sorted sub-list is totally empty. All the elements are present in the unsorted sub-list. We start with the first element in the array.
                    -	Iterate over the array to search for the smallest element.
                    -	Add this element into the sorted sublist, removing it from the unsorted sublist. We can do that by swapping the smallest element, with the element at whose position we want to store it.
                    -	Repeat the above steps until all the elements from the unsorted sublist are moved to the sorted sublist, and the unsorted subarray becomes empty.
                -   Note
                    -   After each iteration, the smallest element among the unsorted elements is placed at the front.

Insertion Sort  -   sorts a list by taking one item at a time and putting it in its correct place among those already sorted
                -   Steps
                    -   The first element in the array is assumed to be sorted. Take the second element and store it separately in key.
                        Compare key with the first element. If the first element is greater than key, then key is placed in front of the first element.
                    -   Now, the first two elements are sorted. Take the third element and compare it with the elements on the left of it.
                        Placed it just behind the element smaller than it. If there is no element smaller than it, then place it at the beginning of the array.
                    -   Similarly, place every unsorted element at its correct position.
                -   Note
                    -   for an ith pass, at a max, we would have i number of comparisons, and i possible swaps.

Shell Sort      -   a generalized version of the insertion sort algorithm.
                -   It first sorts elements that are far apart from each other and successively reduces the interval between the elements to be sorted.
                -	Gap Sequence
                		-	Shell's original sequence: N/2 , N/4 , …, 1
                		-	Knuth's increments: 1, 4, 13, …, (3k – 1) / 2
                -	Steps
                		-	Choose a Gap Sequence:
                				-	The key concept of Shell sort is to sort the elements at a specific interval called the gap.
                				-	A gap sequence defines the intervals at which elements will be compared and sorted.
                				-	Common gap sequences include the Knuth sequence (3k + 1), where k is an integer, but other sequences can be used as well.
                		-	Start with the Widest Gap:
                			-	Begin by starting with the widest gap (largest interval) defined by the gap sequence.
                			-	For each gap, iterate through the array and compare elements that are separated by the current gap.
                			-	Perform insertion sort on each subset of elements at the current gap.
                		-	Decrease the Gap:
                			-	After sorting all subsets at the current gap, reduce the gap size.
                			-	Typically, the gap size is reduced by dividing it by a constant factor until it becomes 1.
                			-	The gap sequence determines how the gap is reduced.
                		-	Continue Sorting:
                			-	Repeat the process of sorting subsets and reducing the gap size until the gap becomes 1.
                			-	At this point, the algorithm performs a final pass using a gap of 1, effectively reducing to a standard insertion sort.
                		-	Final Pass with Gap of 1:
                			-	After reducing the gap to 1, perform a final pass using a gap of 1.
                			-	This final pass effectively reduces Shell sort to a standard insertion sort.
                			-	The insertion sort at this stage takes advantage of the partially sorted nature of the array, leading to improved performance.
                -   Refer   :   https://www.programiz.com/dsa/shell-sort

Merge Sort      -   Merge Sort is one of the most popular sorting algorithms that is based on the principle of Divide and Conquer Algorithm.
                -   Here, a problem is divided into multiple sub-problems. Each sub-problem is solved individually. Finally, sub-problems are combined to form the final solution.
                -   Divide and Conquer Algorithm
                    -   Consider an array A. A subproblem would be to sort a sub-section of this array starting at index p and ending at index r, denoted as A[p..r].
                    -	Divide
                    	-	If q is the half-way point between p and r, then we can split the subarray A[p..r] into two arrays A[p..q] and A[q+1, r].
                    -	Conquer
                    	-	In the conquer step, we try to sort both the subarrays A[p..q] and A[q+1, r]. If we haven't yet reached the base case (array with single element), we again divide both these subarrays and try to sort them.
                    -	Combine
                    	-	When the conquer step reaches the base step and we get two sorted subarrays A[p..q] and A[q+1, r] for array A[p..r], we combine the results by creating a sorted array A[p..r] from two sorted subarrays A[p..q] and A[q+1, r].
                -   Steps
                    -	Our task is to merge two subarrays A[p..q] and A[q+1..r] to create a sorted array A[p..r]. So the inputs to the function are A, p, q and r
                    	-	Create copies of the subarrays L <- A[p..q] and M <- A[q+1..r].
                    	-	Create three pointers i, j and k
                    	-	i maintains current index of L, starting at 0
                    	-	j maintains current index of M, starting at 0
                    	-	k maintains the current index of A[p..q], starting at p.
                    	-	Until we reach the end of either L or M, pick the smaller among the elements from L and M and place them in the correct position at A[p..q]
                    	-	When we run out of elements in either L or M, pick up the remaining elements and put in A[p..q]

Quick Sort      -	Quicksort is a sorting algorithm based on the divide and conquer approach where
                -	An array is divided into subarrays by selecting a pivot element (element selected from the array).
                -	Steps
                	-	While dividing the array, the pivot element should be positioned in such a way that elements less than pivot are kept on the left side and elements greater than pivot are on the right side of the pivot.
                	-	The left and right subarrays are also divided using the same approach. This process continues until each subarray contains a single element.
                	-	At this point, elements are already sorted. Finally, elements are combined to form a sorted array.